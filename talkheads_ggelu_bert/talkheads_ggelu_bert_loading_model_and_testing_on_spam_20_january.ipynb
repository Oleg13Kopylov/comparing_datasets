{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "В этом ноутбуке мы протестируем каждую из двух моделей  BERT with Talking-Heads Attention and Gated GELU (talkheads_ggelu_bert). Одна обучена на spam sms, другая на spam emails. Протестируем каждую модель на каждом из датасетов (spam sms dataset и spam emails dataset). "
      ],
      "metadata": {
        "id": "vqSx-sdfiKsn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'talkheads_ggelu_bert'"
      ],
      "metadata": {
        "id": "drEMotfpsELl"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30x09o7oLp1f",
        "outputId": "352aa463-2797-4b09-8f70-2f13daa5e649"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyvwEI90WqfC",
        "outputId": "c9dca141-7080-4a7e-a3db-5ae632710564"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-text\n",
            "  Downloading tensorflow_text-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow<2.12,>=2.11.0\n",
            "  Downloading tensorflow-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-text) (0.12.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (1.14.1)\n",
            "Collecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-23.1.4-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (1.6.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (0.2.0)\n",
            "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
            "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 KB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (3.1.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (1.21.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (3.3.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (1.51.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (2.2.0)\n",
            "Collecting tensorboard<2.12,>=2.11\n",
            "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m120.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (15.0.6.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (1.15.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (3.19.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (4.4.0)\n",
            "Collecting keras<2.12,>=2.11.0\n",
            "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m88.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (1.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (57.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (0.29.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow<2.12,>=2.11.0->tensorflow-text) (0.38.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (2.16.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (2.25.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (0.4.6)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow<2.12,>=2.11.0->tensorflow-text) (3.0.9)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (5.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (6.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (3.2.2)\n",
            "Installing collected packages: flatbuffers, tensorflow-estimator, keras, tensorboard, tensorflow, tensorflow-text\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "Successfully installed flatbuffers-23.1.4 keras-2.11.0 tensorboard-2.11.2 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-text-2.11.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-text\n",
        "import tensorflow_text as text\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from keras.models import load_model\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hBugLEt9VjLB"
      },
      "outputs": [],
      "source": [
        "spam_sms = 'spam sms'\n",
        "spam_emails = 'spam emails'\n",
        "talkheads_ggelu_bert_trained_on_spam_sms = 'talkheads_ggelu_bert trained on spam sms'\n",
        "talkheads_ggelu_bert_trained_on_spam_emails = 'talkheads_ggelu_bert trained on spam emails'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mshmRa24Vzpm"
      },
      "outputs": [],
      "source": [
        "models_dict = dict()\n",
        "models_dict[talkheads_ggelu_bert_trained_on_spam_sms] = load_model('/content/drive/MyDrive/data_for_colab/talkheads_ggelu_bert_trained_on_spam_sms_20_january')\n",
        "models_dict[talkheads_ggelu_bert_trained_on_spam_emails] = load_model('/content/drive/MyDrive/data_for_colab/talkheads_ggelu_bert_trained_on_spam_emails_20_january')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XjFHJ9bpVV8_"
      },
      "outputs": [],
      "source": [
        "path_to_spam_sms_dataset = '/content/drive/MyDrive/data_for_colab/spam_sms.csv'\n",
        "path_to_spam_emails_dataset = '/content/drive/MyDrive/data_for_colab/spam_emails.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mHdBZrBo8oaQ"
      },
      "outputs": [],
      "source": [
        "def test_model_on_dataset_and_write_results_to_dataframe(model_name=None, dataset_name=None, dataframe_to_write_answer=None):\n",
        "\n",
        "    global spam_sms, spam_emails\n",
        "    global talkheads_ggelu_bert_on_spam_sms\n",
        "    global talkheads_ggelu_bert_on_spam_emails\n",
        "    global models_dict\n",
        "    global path_to_hotel_reviews_dataset\n",
        "    global path_to_movie_reviews_dataset\n",
        "\n",
        "    if model_name is None or dataset_name is None or dataframe_to_write_answer is None:\n",
        "        raise ValueError(\"Wrong arguments passed to function: there are none arguments!\")\n",
        "    if model_name != talkheads_ggelu_bert_trained_on_spam_sms and model_name != talkheads_ggelu_bert_trained_on_spam_emails:\n",
        "        raise ValueError(\"Wrong model_name!\")\n",
        "    if dataset_name != spam_sms and dataset_name != spam_emails:\n",
        "        raise ValueError(\"Wrong dataset_name!\")\n",
        "\n",
        "    model = models_dict[model_name] # загрузили пользователем заданную модель \n",
        "    # (она уже обучена на определенном датасете)\n",
        "\n",
        "    if dataset_name == spam_sms: # if you edit this line, edit the next line too!\n",
        "        df = pd.read_csv(path_to_spam_sms_dataset, encoding = \"ISO-8859-1\")\n",
        "        df.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], inplace=True)\n",
        "        df.columns = ['IS_SPAM', 'DATA_COLUMN']\n",
        "        df['IS_SPAM'] = (df['IS_SPAM'] == 'spam').astype(int)\n",
        "        df_positive = df[df['IS_SPAM']==1]\n",
        "        df_negative = df[df['IS_SPAM']==0]\n",
        "        # Тестовая выборка\n",
        "        n_test = df_negative.shape[0] // 2\n",
        "        df_negative_test = df_negative.tail(n_test)\n",
        "        n_test = df_positive.shape[0] // 2\n",
        "        df_positive_test = df_positive.tail(n_test)\n",
        "        df_balanced_test = pd.concat([df_negative_test, df_positive_test])\n",
        "\n",
        "    elif dataset_name == spam_emails: # if you edit this line, edit the next line too!\n",
        "        df = pd.read_csv(path_to_spam_emails_dataset, encoding = \"ISO-8859-1\")\n",
        "        df.drop(columns=['Unnamed: 0', 'label'], inplace=True)\n",
        "        df.columns = ['DATA_COLUMN', 'IS_SPAM']\n",
        "        df['DATA_COLUMN'] = df['DATA_COLUMN'].apply(lambda x: x.replace('\\r\\n', ' ').replace('\\n', ' '))\n",
        "        df_positive = df[df['IS_SPAM']==1]\n",
        "        df_negative = df[df['IS_SPAM']==0]\n",
        "        # Тестовая выборка\n",
        "        n_test = df_negative.shape[0] // 2\n",
        "        df_negative_test = df_negative.tail(n_test)\n",
        "        n_test = df_positive.shape[0] // 2\n",
        "        df_positive_test = df_positive.tail(n_test)\n",
        "        df_balanced_test = pd.concat([df_negative_test, df_positive_test])\n",
        "\n",
        "    X_test = df_balanced_test['DATA_COLUMN'].squeeze()\n",
        "    y_test = df_balanced_test['IS_SPAM'].squeeze()\n",
        "\n",
        "    y_predicted = model.predict(X_test)\n",
        "    y_predicted = np.where(y_predicted > 0.5, 1, 0)\n",
        "\n",
        "    row_name_in_dataframe_to_write_answer = model_name + ' tested on ' + dataset_name + ' dataset'\n",
        "\n",
        "    dataframe_to_write_answer.loc[row_name_in_dataframe_to_write_answer, 'accuracy'] = accuracy_score(y_test, y_predicted)\n",
        "    dataframe_to_write_answer.loc[row_name_in_dataframe_to_write_answer, 'precision'] = precision_score(y_test, y_predicted)\n",
        "    dataframe_to_write_answer.loc[row_name_in_dataframe_to_write_answer, 'recall'] = recall_score(y_test, y_predicted)\n",
        "    dataframe_to_write_answer.loc[row_name_in_dataframe_to_write_answer, 'f1_score'] =  f1_score(y_test, y_predicted)\n",
        "    print(model_name, ' on dataset', dataset_name, 'result', accuracy_score(y_test, y_predicted), precision_score(y_test, y_predicted), recall_score(y_test, y_predicted), f1_score(y_test, y_predicted) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GJn_O4Are0oU"
      },
      "outputs": [],
      "source": [
        "answer_dataframe = pd.DataFrame(columns=['accuracy', 'precision', 'recall', 'f1_score'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hLmEKFsekAY",
        "outputId": "f7ecc52e-1dee-4a7f-c6d7-d5217ba08319"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "88/88 [==============================] - 42s 429ms/step\n",
            "talkheads_ggelu_bert trained on spam sms  on dataset spam sms result 0.9730700179533214 0.9408284023668639 0.8525469168900804 0.8945147679324895\n",
            "81/81 [==============================] - 34s 428ms/step\n",
            "talkheads_ggelu_bert trained on spam sms  on dataset spam emails result 0.44642166344294004 0.2879353233830846 0.6181575433911882 0.3928722952906237\n",
            "88/88 [==============================] - 37s 413ms/step\n",
            "talkheads_ggelu_bert trained on spam emails  on dataset spam sms result 0.33680430879712747 0.12205128205128205 0.6380697050938338 0.2049074472664658\n",
            "81/81 [==============================] - 34s 420ms/step\n",
            "talkheads_ggelu_bert trained on spam emails  on dataset spam emails result 0.9013539651837524 0.9288194444444444 0.7142857142857143 0.8075471698113208\n"
          ]
        }
      ],
      "source": [
        "for cur_model_name in [talkheads_ggelu_bert_trained_on_spam_sms, talkheads_ggelu_bert_trained_on_spam_emails]:\n",
        "    for cur_dataset_name in [spam_sms, spam_emails]:\n",
        "        test_model_on_dataset_and_write_results_to_dataframe(cur_model_name, cur_dataset_name, answer_dataframe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "8cr_b8y2ekKa",
        "outputId": "68767716-9524-4909-f28e-883a46dd5473"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    accuracy precision  \\\n",
              "talkheads_ggelu_bert trained on spam sms tested...   0.97307  0.940828   \n",
              "talkheads_ggelu_bert trained on spam sms tested...  0.446422  0.287935   \n",
              "talkheads_ggelu_bert trained on spam emails tes...  0.336804  0.122051   \n",
              "talkheads_ggelu_bert trained on spam emails tes...  0.901354  0.928819   \n",
              "\n",
              "                                                      recall  f1_score  \n",
              "talkheads_ggelu_bert trained on spam sms tested...  0.852547  0.894515  \n",
              "talkheads_ggelu_bert trained on spam sms tested...  0.618158  0.392872  \n",
              "talkheads_ggelu_bert trained on spam emails tes...   0.63807  0.204907  \n",
              "talkheads_ggelu_bert trained on spam emails tes...  0.714286  0.807547  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ddc293e1-eabd-4a3e-9493-ac7d7ea9e789\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>talkheads_ggelu_bert trained on spam sms tested on spam sms dataset</th>\n",
              "      <td>0.97307</td>\n",
              "      <td>0.940828</td>\n",
              "      <td>0.852547</td>\n",
              "      <td>0.894515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>talkheads_ggelu_bert trained on spam sms tested on spam emails dataset</th>\n",
              "      <td>0.446422</td>\n",
              "      <td>0.287935</td>\n",
              "      <td>0.618158</td>\n",
              "      <td>0.392872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>talkheads_ggelu_bert trained on spam emails tested on spam sms dataset</th>\n",
              "      <td>0.336804</td>\n",
              "      <td>0.122051</td>\n",
              "      <td>0.63807</td>\n",
              "      <td>0.204907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>talkheads_ggelu_bert trained on spam emails tested on spam emails dataset</th>\n",
              "      <td>0.901354</td>\n",
              "      <td>0.928819</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.807547</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ddc293e1-eabd-4a3e-9493-ac7d7ea9e789')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ddc293e1-eabd-4a3e-9493-ac7d7ea9e789 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ddc293e1-eabd-4a3e-9493-ac7d7ea9e789');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "answer_dataframe\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сохраняем dataframe"
      ],
      "metadata": {
        "id": "C4IAVz4brgfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "name_for_dataframe = model_name + ' on spam testing result'"
      ],
      "metadata": {
        "id": "NRmtaZOHrx4L"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer_dataframe.to_csv('/content/drive/MyDrive/data_for_colab/dataframes/test_quality/' + name_for_dataframe + '.csv')"
      ],
      "metadata": {
        "id": "ajYptTbnru0J"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qECTe8VYsGe1"
      },
      "execution_count": 12,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}